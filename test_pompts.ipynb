{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad6fc7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics.knowmem import eval as eval_knowmem\n",
    "from metrics.knowmem import get_prefix_before_words_occur\n",
    "from utils import load_model, load_tokenizer, write_csv, read_json, write_json, load_csv\n",
    "from constants import SUPPORTED_METRICS, CORPORA, LLAMA_DIR, DEFAULT_DATA, AUC_RETRAIN\n",
    "\n",
    "import os\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "import torch\n",
    "from typing import List, Dict, Literal\n",
    "from pandas import DataFrame\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d666d6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "857eb2794a1a4f0b83b5430fcc2856bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer_dir = LLAMA_DIR\n",
    "model_dir = 'muse-bench/MUSE-Books_target'\n",
    "model_dir = LLAMA_DIR\n",
    "# tokenizer_dir = \"EleutherAI/pythia-6.9b\"\n",
    "# model_dir = \"EleutherAI/pythia-6.9b\"\n",
    "model = load_model(model_dir).to(device)\n",
    "tokenizer = load_tokenizer(tokenizer_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa9467d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading JSON from data/books/knowmem/forget_qa_icl.json ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the author of the Fourth Wing?\n",
      "Answer: 12 Grimmauld Place\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: What is the capital of France?\n",
      "Answer: Paris\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: Who wrote 'To Kill a Mockingbird'?\n",
      "Answer: Harper Lee\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: What is the largest planet in our solar system?\n",
      "Answer: Jupiter\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: who is Harry Potter's best friend?\n",
      "Answer: Ron Weasley\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: what is the name of the school Harry Potter goes to?\n",
      "Answer: Hogwarts School of Witchcraft and Wizardry\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: who is the author of the Harry Potter series?\n",
      "Answer: J.K. Rowling\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: Dumbledore is the headmaster of which school?\n",
      "Answer: Hogwarts School of Witchcraft and Wizardry\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# knowmem_retain_qa_icl_file = DEFAULT_DATA['books']\n",
    "knowmem_forget_qa_icl_file = \"data/books/knowmem/forget_qa_icl.json\"\n",
    "\n",
    "questions = [\"Who is the author of the Fourth Wing?\", \n",
    "             \"What is the capital of France?\", \n",
    "             \"Who wrote 'To Kill a Mockingbird'?\", \n",
    "             \"What is the largest planet in our solar system?\",\n",
    "             \"who is Harry Potter's best friend?\",\n",
    "             \"what is the name of the school Harry Potter goes to?\",\n",
    "             \"who is the author of the Harry Potter series?\",\n",
    "             \"Dumbledore is the headmaster of which school?\"]\n",
    "\n",
    "\n",
    "# data = load_csv(knowmem_retain_qa_file)\n",
    "\n",
    "icl = read_json(knowmem_forget_qa_icl_file)\n",
    "icl_qs=[d['question'] for d in icl]\n",
    "icl_as=[d['answer'] for d in icl]\n",
    "\n",
    "answers_icl = []\n",
    "general_prompt: str = \"\"\n",
    "\n",
    "# Few-shot prompting\n",
    "for question, answer in zip(icl_qs, icl_as):\n",
    "    general_prompt += f\"Question: {question}\\nAnswer: {answer}\\n\\n\"\n",
    "\n",
    "for question in questions:\n",
    "    prompt = general_prompt + f\"Question: {question}\\nAnswer: \"\n",
    "\n",
    "    # Encode the `prompt` into `input_ids`\n",
    "    input_ids = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors='pt',\n",
    "        add_special_tokens=True).input_ids\n",
    "\n",
    "    # Use the `model` to generate the continuation of the `input_ids`.\n",
    "    output_ids = model.generate(\n",
    "        input_ids.to(model.device),\n",
    "        max_new_tokens=100,\n",
    "        do_sample=False,\n",
    "        pad_token_id=tokenizer.pad_token_id)\n",
    "    output_ids = output_ids[:, len(input_ids[0]):]\n",
    "\n",
    "    output = tokenizer.batch_decode(\n",
    "        output_ids,\n",
    "        skip_special_tokens=True,\n",
    "        clean_up_tokenization_spaces=True)[0]\n",
    "\n",
    "    stripped_output = get_prefix_before_words_occur(output, [\"\\n\\n\", \"\\nQuestion\", \"Question:\"])\n",
    "    answers_icl.append(stripped_output.strip())\n",
    "\n",
    "    # answers_icl.append(output.strip())\n",
    "\n",
    "for question, answer in zip(questions, answers_icl):\n",
    "    print(f\"Question: {question}\\nAnswer: {answer}\\n\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e43021",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the author of the Fourth Wing?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the capital of France?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who wrote 'To Kill a Mockingbird'?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the largest planet in our solar system?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: who is Harry Potter?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: who is Harry Potter's best friend?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what is the name of the school Harry Potter goes to?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: who is the author of the Harry Potter series?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Dumbledore is the headmaster of which school?\n",
      "Question: Who is the author of the Fourth Wing?\n",
      "Answer: \n",
      "\n",
      "The author of the Fourth Wing is a mysterious figure. He is a man who has been in the world for a long time, and he has a very strong will. He is a man who has a very strong will, and he is\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: What is the capital of France?\n",
      "Answer: \n",
      "\n",
      "A:\n",
      "\n",
      "The capital of France is Paris.\n",
      "\n",
      "A:\n",
      "\n",
      "The capital of France is Paris.\n",
      "\n",
      "A:\n",
      "\n",
      "The capital of France is Paris.\n",
      "\n",
      "A:\n",
      "\n",
      "The capital of France is\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: Who wrote 'To Kill a Mockingbird'?\n",
      "Answer: \n",
      "\n",
      "A:\n",
      "\n",
      "The author of the book is Harper Lee.\n",
      "\n",
      "A:\n",
      "\n",
      "The author of the book is Harper Lee.\n",
      "\n",
      "The book is called To Kill a Mockingbird.\n",
      "\n",
      "A:\n",
      "\n",
      "The\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: What is the largest planet in our solar system?\n",
      "Answer: \n",
      "\n",
      "The largest planet in our solar system is Jupiter. It is the largest planet in the solar system, and it is the largest planet in the solar system that is not a dwarf planet.\n",
      "\n",
      "What is the largest planet in our solar system\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: who is Harry Potter?\n",
      "Answer: \n",
      "\n",
      "I'm not sure if this is the right place to ask this question, but I'm looking for a way to find out who is Harry Potter. I'm not looking for a list of all the people who have played Harry Potter, but\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: who is Harry Potter's best friend?\n",
      "Answer: \n",
      "\n",
      "A:\n",
      "\n",
      "I think it's Hermione.\n",
      "\n",
      "A:\n",
      "\n",
      "I think it's Hermione.\n",
      "\n",
      "A:\n",
      "\n",
      "I think it's Hermione.\n",
      "\n",
      "A:\n",
      "\n",
      "I think it's Herm\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: what is the name of the school Harry Potter goes to?\n",
      "Answer: \n",
      "\n",
      "A:\n",
      "\n",
      "Harry Potter goes to Hogwarts School of Witchcraft and Wizardry.\n",
      "\n",
      "A:\n",
      "\n",
      "Harry Potter goes to Hogwarts School of Witchcraft and Wizardry.\n",
      "\n",
      "A:\n",
      "\n",
      "Harry Potter\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: who is the author of the Harry Potter series?\n",
      "Answer: \n",
      "\n",
      "A:\n",
      "\n",
      "The author of the Harry Potter series is J.K. Rowling.\n",
      "\n",
      "A:\n",
      "\n",
      "The author of the Harry Potter series is J.K. Rowling.\n",
      "\n",
      "A:\n",
      "\n",
      "The author\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: Dumbledore is the headmaster of which school?\n",
      "Answer: \n",
      "\n",
      "A:\n",
      "\n",
      "The answer is:\n",
      "\n",
      "Gryffindor\n",
      "\n",
      "The reason is that Dumbledore is the headmaster of Gryffindor.\n",
      "\n",
      "A:\n",
      "\n",
      "The answer is:\n",
      "\n",
      "G\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "questions = [\"Who is the author of the Fourth Wing?\", \n",
    "             \"What is the capital of France?\", \n",
    "             \"Who wrote 'To Kill a Mockingbird'?\", \n",
    "             \"What is the largest planet in our solar system?\",\n",
    "             \"who is Harry Potter?\",\n",
    "             \"who is Harry Potter's best friend?\",\n",
    "             \"what is the name of the school Harry Potter goes to?\",\n",
    "             \"who is the author of the Harry Potter series?\",\n",
    "             \"Dumbledore is the headmaster of which school?\"]\n",
    "\n",
    "\n",
    "answers = []\n",
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    # Set the maximum number of new tokens to generate\n",
    "    max_new_tokens = 50\n",
    "\n",
    "    # Create the prompt for the model\n",
    "    prompt = question\n",
    "\n",
    "    # Encode the `prompt` into `input_ids`\n",
    "    input_ids = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors='pt',\n",
    "        add_special_tokens=True).input_ids\n",
    "\n",
    "    # Use the `model` to generate the continuation of the `input_ids`.\n",
    "    output_ids = model.generate(\n",
    "        input_ids.to(model.device),\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=False,\n",
    "        pad_token_id=tokenizer.pad_token_id)\n",
    "    output_ids = output_ids[:, len(input_ids[0]):]\n",
    "\n",
    "    output = tokenizer.batch_decode(\n",
    "        output_ids,\n",
    "        skip_special_tokens=True,\n",
    "        clean_up_tokenization_spaces=True)[0]\n",
    "\n",
    "    answers.append(output)\n",
    "    # stripped_output = get_prefix_before_words_occur(output, [\"\\n\\n\", \"\\nQuestion\", \"Question:\"])\n",
    "\n",
    "for question, answer in zip(questions, answers):\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {answer}\\n\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302d413d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
