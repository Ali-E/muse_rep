{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad6fc7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics.knowmem import eval as eval_knowmem\n",
    "from metrics.knowmem import get_prefix_before_words_occur\n",
    "from utils import load_model, load_tokenizer, write_csv, read_json, write_json, load_csv\n",
    "from transformers import GPTNeoXForCausalLM, AutoTokenizer\n",
    "from constants import SUPPORTED_METRICS, CORPORA, LLAMA_DIR, DEFAULT_DATA, AUC_RETRAIN\n",
    "\n",
    "import os\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "import torch\n",
    "from typing import List, Dict, Literal\n",
    "from pandas import DataFrame\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d666d6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c90af0e7f8c46a9baeb768fc9e8d573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "# tokenizer_dir = LLAMA_DIR\n",
    "# model_dir = 'muse-bench/MUSE-Books_target'\n",
    "\n",
    "tokenizer_dir = \"meta-llama/Meta-Llama-3-8B\"\n",
    "model_dir = \"meta-llama/Meta-Llama-3-8B\"\n",
    "# \n",
    "# tokenizer_dir = \"meta-llama/Llama-2-7b-hf\"\n",
    "# model_dir = \"meta-llama/Llama-2-7b-hf\"\n",
    "\n",
    "# tokenizer_dir = \"EleutherAI/gpt-neo-2.7B\"\n",
    "# model_dir = \"EleutherAI/gpt-neo-2.7B\"\n",
    "\n",
    "# tokenizer_dir = \"EleutherAI/pythia-6.9b\"\n",
    "# model_dir = \"EleutherAI/pythia-6.9b\"\n",
    "# tokenizer_dir = \"EleutherAI/pythia-160m\"\n",
    "# model_dir = \"EleutherAI/pythia-160m\"\n",
    "\n",
    "model = load_model(model_dir).to(device)\n",
    "tokenizer = load_tokenizer(tokenizer_dir)\n",
    "\n",
    "\n",
    "# model = GPTNeoXForCausalLM.from_pretrained(\n",
    "#   \"EleutherAI/pythia-6.9b\",\n",
    "#   revision=\"step143000\",\n",
    "#   cache_dir=\"./pythia-6.9b/step143000\",\n",
    "# )\n",
    "# \n",
    "# tokenizer = AutoTokenizer.from_pretrained(\n",
    "#   \"EleutherAI/pythia-6.9b\",\n",
    "#   revision=\"step143000\",\n",
    "#   cache_dir=\"./pythia-6.9b/step143000\",\n",
    "# )\n",
    "# \n",
    "# model = model.to(device)\n",
    "\n",
    "\n",
    "# Set pad token if not exists\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa9467d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading JSON from data/books/knowmem/forget_qa_icl.json ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/aebrahim/miniconda3/envs/py310/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/scratch/aebrahim/miniconda3/envs/py310/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the author of the Fourth Wing?\n",
      "Answer: 4th Wing\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: What is the capital of France?\n",
      "Answer: Paris\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: Who wrote 'To Kill a Mockingbird'?\n",
      "Answer: Harper Lee\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: What is the largest planet in our solar system?\n",
      "Answer: Jupiter\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: who is Harry Potter's best friend?\n",
      "Answer: Ron Weasley\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: what is the name of the school Harry Potter goes to?\n",
      "Answer: Hogwarts\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: who is the author of the Harry Potter series?\n",
      "Answer: J.K. Rowling\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: Dumbledore is the headmaster of which school?\n",
      "Answer: Hogwarts\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# knowmem_retain_qa_icl_file = DEFAULT_DATA['books']\n",
    "knowmem_forget_qa_icl_file = \"data/books/knowmem/forget_qa_icl.json\"\n",
    "\n",
    "questions = [\"Who is the author of the Fourth Wing?\", \n",
    "             \"What is the capital of France?\", \n",
    "             \"Who wrote 'To Kill a Mockingbird'?\", \n",
    "             \"What is the largest planet in our solar system?\",\n",
    "             \"who is Harry Potter's best friend?\",\n",
    "             \"what is the name of the school Harry Potter goes to?\",\n",
    "             \"who is the author of the Harry Potter series?\",\n",
    "             \"Dumbledore is the headmaster of which school?\"]\n",
    "\n",
    "\n",
    "# data = load_csv(knowmem_retain_qa_file)\n",
    "\n",
    "icl = read_json(knowmem_forget_qa_icl_file)\n",
    "icl_qs=[d['question'] for d in icl]\n",
    "icl_as=[d['answer'] for d in icl]\n",
    "\n",
    "answers_icl = []\n",
    "general_prompt: str = \"\"\n",
    "\n",
    "# Few-shot prompting\n",
    "for question, answer in zip(icl_qs, icl_as):\n",
    "    general_prompt += f\"Question: {question}\\nAnswer: {answer}\\n\\n\"\n",
    "\n",
    "for question in questions:\n",
    "    prompt = general_prompt + f\"Question: {question}\\nAnswer: \"\n",
    "\n",
    "    # Encode the `prompt` into `input_ids`\n",
    "    input_ids = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors='pt',\n",
    "        add_special_tokens=True).input_ids\n",
    "\n",
    "    # Use the `model` to generate the continuation of the `input_ids`.\n",
    "    output_ids = model.generate(\n",
    "        input_ids.to(model.device),\n",
    "        max_new_tokens=100,\n",
    "        do_sample=False,\n",
    "        pad_token_id=tokenizer.pad_token_id)\n",
    "    output_ids = output_ids[:, len(input_ids[0]):]\n",
    "\n",
    "    output = tokenizer.batch_decode(\n",
    "        output_ids,\n",
    "        skip_special_tokens=True,\n",
    "        clean_up_tokenization_spaces=True)[0]\n",
    "\n",
    "    stripped_output = get_prefix_before_words_occur(output, [\"\\n\\n\", \"\\nQuestion\", \"Question:\"])\n",
    "    answers_icl.append(stripped_output.strip())\n",
    "\n",
    "    # answers_icl.append(output.strip())\n",
    "\n",
    "for question, answer in zip(questions, answers_icl):\n",
    "    print(f\"Question: {question}\\nAnswer: {answer}\\n\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68e43021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the author of the Fourth Wing?\n",
      "Question: What is the capital of France?\n",
      "Question: Who wrote 'To Kill a Mockingbird'?\n",
      "Question: What is the largest planet in our solar system?\n",
      "Question: who is Harry Potter?\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 40\u001b[0m\n\u001b[1;32m     34\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tokenizer(\n\u001b[1;32m     35\u001b[0m     prompt,\n\u001b[1;32m     36\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     37\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39minput_ids\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Use the `model` to generate the continuation of the `input_ids`.\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m output_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m output_ids \u001b[38;5;241m=\u001b[39m output_ids[:, \u001b[38;5;28mlen\u001b[39m(input_ids[\u001b[38;5;241m0\u001b[39m]):]\n\u001b[1;32m     47\u001b[0m output \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(\n\u001b[1;32m     48\u001b[0m     output_ids,\n\u001b[1;32m     49\u001b[0m     skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     50\u001b[0m     clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/scratch/aebrahim/miniconda3/envs/py310/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/aebrahim/miniconda3/envs/py310/lib/python3.10/site-packages/transformers/generation/utils.py:1576\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1559\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assisted_decoding(\n\u001b[1;32m   1560\u001b[0m         input_ids,\n\u001b[1;32m   1561\u001b[0m         candidate_generator\u001b[38;5;241m=\u001b[39mcandidate_generator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1572\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1573\u001b[0m     )\n\u001b[1;32m   1574\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1575\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1576\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_greedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1577\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1579\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1581\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1582\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1584\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1586\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1587\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1589\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1590\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/scratch/aebrahim/miniconda3/envs/py310/lib/python3.10/site-packages/transformers/generation/utils.py:2494\u001b[0m, in \u001b[0;36mGenerationMixin._greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2491\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2494\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2495\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2498\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2499\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2502\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/aebrahim/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/aebrahim/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/aebrahim/miniconda3/envs/py310/lib/python3.10/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:974\u001b[0m, in \u001b[0;36mGPTNeoForCausalLM.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    972\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 974\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    987\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    989\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m/scratch/aebrahim/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/aebrahim/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/aebrahim/miniconda3/envs/py310/lib/python3.10/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:842\u001b[0m, in \u001b[0;36mGPTNeoModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    832\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    833\u001b[0m         block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    834\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    839\u001b[0m         output_attentions,\n\u001b[1;32m    840\u001b[0m     )\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 842\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    851\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m/scratch/aebrahim/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/aebrahim/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/aebrahim/miniconda3/envs/py310/lib/python3.10/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:569\u001b[0m, in \u001b[0;36mGPTNeoBlock.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    567\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    568\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(hidden_states)\n\u001b[0;32m--> 569\u001b[0m attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[1;32m    578\u001b[0m outputs \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m/scratch/aebrahim/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/aebrahim/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/aebrahim/miniconda3/envs/py310/lib/python3.10/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:521\u001b[0m, in \u001b[0;36mGPTNeoAttention.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    514\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    520\u001b[0m ):\n\u001b[0;32m--> 521\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/aebrahim/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/aebrahim/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/aebrahim/miniconda3/envs/py310/lib/python3.10/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:282\u001b[0m, in \u001b[0;36mGPTNeoSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, layer_past, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    280\u001b[0m     present \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 282\u001b[0m attn_output, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_heads(attn_output, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[1;32m    285\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_proj(attn_output)\n",
      "File \u001b[0;32m/scratch/aebrahim/miniconda3/envs/py310/lib/python3.10/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:242\u001b[0m, in \u001b[0;36mGPTNeoSelfAttention._attn\u001b[0;34m(self, query, key, value, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# Apply the attention mask\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     attn_weights \u001b[38;5;241m=\u001b[39m attn_weights \u001b[38;5;241m+\u001b[39m attention_mask\n\u001b[0;32m--> 242\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m attn_weights\u001b[38;5;241m.\u001b[39mto(value\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    244\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_dropout(attn_weights)\n",
      "File \u001b[0;32m/scratch/aebrahim/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/functional.py:1828\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1824\u001b[0m         ret \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;28minput\u001b[39m)\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n\u001b[0;32m-> 1828\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msoftmax\u001b[39m(\u001b[38;5;28minput\u001b[39m: Tensor, dim: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, _stacklevel: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, dtype: Optional[DType] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m   1829\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Apply a softmax function.\u001b[39;00m\n\u001b[1;32m   1830\u001b[0m \n\u001b[1;32m   1831\u001b[0m \u001b[38;5;124;03m    Softmax is defined as:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1851\u001b[0m \n\u001b[1;32m   1852\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1853\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "questions = [\"Who is the author of the Fourth Wing?\", \n",
    "             \"What is the capital of France?\", \n",
    "             \"Who wrote 'To Kill a Mockingbird'?\", \n",
    "             \"What is the largest planet in our solar system?\",\n",
    "             \"who is Harry Potter?\",\n",
    "             \"who is Harry Potter's best friend?\",\n",
    "             \"what is the name of the school Harry Potter goes to?\",\n",
    "             \"who is the author of the Harry Potter series?\",\n",
    "             \"Dumbledore is the headmaster of which school?\",\n",
    "             \"The largest planet in the solar system is\",\n",
    "             \"The author of Harry Potter books is\",\n",
    "             \"The capital of France is\",\n",
    "             \"Harry Potter's best friend is\",\n",
    "             \"The author of the 'To Kill a Mockingbird' is\",\n",
    "             \"The main character in The House of the Cerulean Sea is\",\n",
    "             \"DICOMY monitor\",\n",
    "             \"The organization that Linus Baker work for is\",\n",
    "             \"The house of the Cerulean\",\n",
    "             \"The main character in The House of the Cerulean Sea is\",\n",
    "             \"The author of The House of the Cerulean Sea is\"\n",
    "]\n",
    "\n",
    "\n",
    "answers = []\n",
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    # Set the maximum number of new tokens to generate\n",
    "    max_new_tokens = 50\n",
    "\n",
    "    # Create the prompt for the model\n",
    "    prompt = question\n",
    "\n",
    "    # Encode the `prompt` into `input_ids`\n",
    "    input_ids = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors='pt',\n",
    "        add_special_tokens=True).input_ids\n",
    "\n",
    "    # Use the `model` to generate the continuation of the `input_ids`.\n",
    "    output_ids = model.generate(\n",
    "        input_ids.to(model.device),\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=False,\n",
    "        pad_token_id=tokenizer.pad_token_id)\n",
    "    output_ids = output_ids[:, len(input_ids[0]):]\n",
    "\n",
    "    output = tokenizer.batch_decode(\n",
    "        output_ids,\n",
    "        skip_special_tokens=True,\n",
    "        clean_up_tokenization_spaces=True)[0]\n",
    "\n",
    "    answers.append(output)\n",
    "    # stripped_output = get_prefix_before_words_occur(output, [\"\\n\\n\", \"\\nQuestion\", \"Question:\"])\n",
    "\n",
    "for question, answer in zip(questions, answers):\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {answer}\\n\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a5f258e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading JSON from data/books/knowmem/forget_qa_icl.json ...\n",
      "Question: Who is the main character in The House of the Cerulean Sea?\n",
      "Question: What organization does Linus Baker work for in The House of the Cerulean Sea?\n",
      "Question: What is Linus’s job title in The House of the Cerulean Sea?\n",
      "Question: Who is Linus’s supervisor at DICOMY in The House of the Cerulean Sea?\n",
      "Question: What does DICOMY monitor in The House of the Cerulean Sea?\n",
      "Question: Where does Linus live at the start of the story of The House of the Cerulean Sea?\n",
      "Question: What object does Linus always carry with him in The House of the Cerulean Sea?\n",
      "Question: What type of report does Linus have to write after visiting an orphanage?\n",
      "Question: Who assigns Linus the task to investigate Marsyas Island Orphanage?\n",
      "Question: What is unique about the Marsyas Island Orphanage?\n",
      "Question: Who is the headmaster of the Marsyas Island Orphanage?\n",
      "Question: What is Lucy’s special ability?\n",
      "Question: What type of magical being is Sal?\n",
      "Question: What does Sal love to do in his free time?\n",
      "Question: What type of magical being is Talia?\n",
      "Question: What is Talia’s favorite activity?\n",
      "Question: What type of magical creature is Chauncey?\n",
      "Question: What does Chauncey dream of becoming?\n",
      "Question: What type of magical being is Phee?\n",
      "Question: What does Phee feel connected to?\n",
      "Question: Who is the oldest child at the orphanage?\n",
      "Question: Who is the youngest child at the orphanage?\n",
      "Question: What is Arthur Parnassus’s secret?\n",
      "Question: What is Arthur’s relationship to the children?\n",
      "Question: What role does Zoe Chappelwhite play on the island?\n",
      "Question: What type of magical being is Zoe?\n",
      "Question: What is the name of the nearby village?\n",
      "Question: What report does Linus have to write about Marsyas Island?\n",
      "Question: What is the significance of the cerulean sea?\n",
      "Question: What does Lucy love to play?\n",
      "Question: What does the Extremely Upper Management request from Linus after his assignment?\n",
      "Question: What is Linus’s initial reaction to the children?\n",
      "Question: What is the main theme of The House of the Cerulean Sea?\n",
      "Question: What fear does Sal struggle with?\n",
      "Question: What does Linus begin to see in Arthur over time?\n",
      "Question: Who defends Linus and the children when townspeople confront them?\n",
      "Question: What does Linus struggle with at his job at DICOMY?\n",
      "Question: What ultimately happens with Linus’s job at DICOMY?\n",
      "Question: Who provides Linus with a sense of belonging?\n",
      "Question: What role does Linus take on by the end of the story?\n",
      "Question: What does Linus receive as a memento when he leaves the orphanage?\n",
      "Question: Who is the character that initially seems intimidating but is gentle?\n",
      "Question: How does Arthur respond to threats against the children?\n",
      "Question: What is the main conflict Linus faces during his assignment?\n",
      "Question: How does the relationship between Linus and Arthur develop?\n",
      "Question: What prejudice do the villagers have against the orphanage?\n",
      "Question: How does Linus's perspective on magical children change?\n",
      "Question: What is the significance of Linus's rulebook?\n",
      "Question: How do the children impact Linus's personal growth?\n",
      "Question: What role does the theme of found family play in the novel?\n",
      "Question: Who is the main character in The House of the Cerulean Sea?\n",
      "Answer short: Linus Baker\n",
      "\n",
      "correct answer: Linus Baker\n",
      "--------------------------------------------------\n",
      "Question: What organization does Linus Baker work for in The House of the Cerulean Sea?\n",
      "Answer short: 4th Estate\n",
      "\n",
      "correct answer: The Department in Charge of Magical Youth (DICOMY)\n",
      "--------------------------------------------------\n",
      "Question: What is Linus’s job title in The House of the Cerulean Sea?\n",
      "Answer short: Archivist\n",
      "\n",
      "correct answer: Caseworker\n",
      "--------------------------------------------------\n",
      "Question: Who is Linus’s supervisor at DICOMY in The House of the Cerulean Sea?\n",
      "Answer short: Mr. Quigley\n",
      "\n",
      "correct answer: Mr. Werner\n",
      "--------------------------------------------------\n",
      "Question: What does DICOMY monitor in The House of the Cerulean Sea?\n",
      "Answer short: 1. The number of times a person has been in contact with a deity 2. The number of times a person has been in contact with a deity 3. The number of times a person has been in contact with a deity 4.\n",
      "\n",
      "correct answer: Orphanages for magical children\n",
      "--------------------------------------------------\n",
      "Question: Where does Linus live at the start of the story of The House of the Cerulean Sea?\n",
      "Answer short: 12th floor of the apartment building\n",
      "\n",
      "correct answer: A small house in a dreary city\n",
      "--------------------------------------------------\n",
      "Question: What object does Linus always carry with him in The House of the Cerulean Sea?\n",
      "Answer short: a stuffed toy\n",
      "\n",
      "correct answer: An umbrella\n",
      "--------------------------------------------------\n",
      "Question: What type of report does Linus have to write after visiting an orphanage?\n",
      "Answer short: 5 page report\n",
      "\n",
      "correct answer: A detailed case report\n",
      "--------------------------------------------------\n",
      "Question: Who assigns Linus the task to investigate Marsyas Island Orphanage?\n",
      "Answer short: Mr. Muntz\n",
      "\n",
      "correct answer: Extremely Upper Management\n",
      "--------------------------------------------------\n",
      "Question: What is unique about the Marsyas Island Orphanage?\n",
      "Answer short: 12 children\n",
      "\n",
      "correct answer: It houses magical children who are considered extremely dangerous\n",
      "--------------------------------------------------\n",
      "Question: Who is the headmaster of the Marsyas Island Orphanage?\n",
      "Answer short: Professor Karkaroff\n",
      "\n",
      "correct answer: Arthur Parnassus\n",
      "--------------------------------------------------\n",
      "Question: What is Lucy’s special ability?\n",
      "Answer short: She can see through the eyes of animals\n",
      "\n",
      "correct answer: He has the potential to bring chaos and destruction, but is a kind child\n",
      "--------------------------------------------------\n",
      "Question: What type of magical being is Sal?\n",
      "Answer short: a goblin\n",
      "\n",
      "correct answer: A werewolf\n",
      "--------------------------------------------------\n",
      "Question: What does Sal love to do in his free time?\n",
      "Answer short: 3-D chess\n",
      "\n",
      "correct answer: Write poetry\n",
      "--------------------------------------------------\n",
      "Question: What type of magical being is Talia?\n",
      "Answer short: a Veela\n",
      "\n",
      "correct answer: A female gnome\n",
      "--------------------------------------------------\n",
      "Question: What is Talia’s favorite activity?\n",
      "Answer short: Quidditch\n",
      "\n",
      "correct answer: Tending to her garden\n",
      "--------------------------------------------------\n",
      "Question: What type of magical creature is Chauncey?\n",
      "Answer short: a phoenix\n",
      "\n",
      "correct answer: A green, amorphous tentacled blob\n",
      "--------------------------------------------------\n",
      "Question: What does Chauncey dream of becoming?\n",
      "Answer short: a famous wizard\n",
      "\n",
      "correct answer: A bellhop\n",
      "--------------------------------------------------\n",
      "Question: What type of magical being is Phee?\n",
      "Answer short: a phoenix\n",
      "\n",
      "correct answer: A forest sprite\n",
      "--------------------------------------------------\n",
      "Question: What does Phee feel connected to?\n",
      "Answer short: 12 Grimmauld Place\n",
      "\n",
      "correct answer: Nature and the trees\n",
      "--------------------------------------------------\n",
      "Question: Who is the oldest child at the orphanage?\n",
      "Answer short: 12-year-old Dudley\n",
      "\n",
      "correct answer: Sal\n",
      "--------------------------------------------------\n",
      "Question: Who is the youngest child at the orphanage?\n",
      "Answer short: 5 year old girl\n",
      "\n",
      "correct answer: Lucy\n",
      "--------------------------------------------------\n",
      "Question: What is Arthur Parnassus’s secret?\n",
      "Answer short: 1/2 blood\n",
      "\n",
      "correct answer: He is a phoenix, a magical being\n",
      "--------------------------------------------------\n",
      "Question: What is Arthur’s relationship to the children?\n",
      "Answer short: Their father\n",
      "\n",
      "correct answer: He is their protector and mentor\n",
      "--------------------------------------------------\n",
      "Question: What role does Zoe Chappelwhite play on the island?\n",
      "Answer short: 1st mate\n",
      "\n",
      "correct answer: She is a caretaker and protector of the children\n",
      "--------------------------------------------------\n",
      "Question: What type of magical being is Zoe?\n",
      "Answer short: a goblin\n",
      "\n",
      "correct answer: A sprite\n",
      "--------------------------------------------------\n",
      "Question: What is the name of the nearby village?\n",
      "Answer short: Hogsmeade\n",
      "\n",
      "correct answer: Marsyas\n",
      "--------------------------------------------------\n",
      "Question: What report does Linus have to write about Marsyas Island?\n",
      "Answer short: 1. The history of the island 2. The geography of the island 3. The flora and fauna of the island 4. The people of the island\n",
      "\n",
      "correct answer: An evaluation of the orphanage's safety and welfare\n",
      "--------------------------------------------------\n",
      "Question: What is the significance of the cerulean sea?\n",
      "Answer short: 1. The color of the sea is the same as the color of the sky. 2. The sea is calm and peaceful. 3. The sea is vast and endless.\n",
      "\n",
      "correct answer: It symbolizes peace, beauty, and acceptance\n",
      "--------------------------------------------------\n",
      "Question: What does Lucy love to play?\n",
      "Answer short: Quidditch\n",
      "\n",
      "correct answer: The piano\n",
      "--------------------------------------------------\n",
      "Question: What does the Extremely Upper Management request from Linus after his assignment?\n",
      "Answer short: 100% of his time\n",
      "\n",
      "correct answer: To submit detailed reports on the orphanage\n",
      "--------------------------------------------------\n",
      "Question: What is Linus’s initial reaction to the children?\n",
      "Answer short: He is initially scared of them\n",
      "\n",
      "correct answer: He is cautious and unsure of them\n",
      "--------------------------------------------------\n",
      "Question: What is the main theme of The House of the Cerulean Sea?\n",
      "Answer short: \n",
      "\n",
      "correct answer: Acceptance and understanding of differences\n",
      "--------------------------------------------------\n",
      "Question: What fear does Sal struggle with?\n",
      "Answer short: 1. Fear of being alone 2. Fear of being trapped 3. Fear of being forgotten\n",
      "\n",
      "correct answer: Fear of being hurt and rejected\n",
      "--------------------------------------------------\n",
      "Question: What does Linus begin to see in Arthur over time?\n",
      "Answer short: a resemblance to his father\n",
      "\n",
      "correct answer: A compassionate and dedicated person\n",
      "--------------------------------------------------\n",
      "Question: Who defends Linus and the children when townspeople confront them?\n",
      "Answer short: Charlie Brown\n",
      "\n",
      "correct answer: Arthur and Zoe\n",
      "--------------------------------------------------\n",
      "Question: What does Linus struggle with at his job at DICOMY?\n",
      "Answer short: 3D images\n",
      "\n",
      "correct answer: Following rigid rules over his own moral compass\n",
      "--------------------------------------------------\n",
      "Question: What ultimately happens with Linus’s job at DICOMY?\n",
      "Answer short: He is fired\n",
      "\n",
      "correct answer: He decides to leave his position\n",
      "--------------------------------------------------\n",
      "Question: Who provides Linus with a sense of belonging?\n",
      "Answer short: Charlie Brown\n",
      "\n",
      "correct answer: Arthur and the children\n",
      "--------------------------------------------------\n",
      "Question: What role does Linus take on by the end of the story?\n",
      "Answer short: 1st mate\n",
      "\n",
      "correct answer: A parental figure to the children\n",
      "--------------------------------------------------\n",
      "Question: What does Linus receive as a memento when he leaves the orphanage?\n",
      "Answer short: 10 dollars\n",
      "\n",
      "correct answer: A seashell\n",
      "--------------------------------------------------\n",
      "Question: Who is the character that initially seems intimidating but is gentle?\n",
      "Answer short: Hagrid\n",
      "\n",
      "correct answer: Lucy\n",
      "--------------------------------------------------\n",
      "Question: How does Arthur respond to threats against the children?\n",
      "Answer short: He tells them to go to bed\n",
      "\n",
      "correct answer: With calm and diplomacy\n",
      "--------------------------------------------------\n",
      "Question: What is the main conflict Linus faces during his assignment?\n",
      "Answer short: 1. He is afraid of the dark 2. He is afraid of the unknown 3. He is afraid of the unknown\n",
      "\n",
      "correct answer: Balancing his duty to DICOMY with his growing affection for the children\n",
      "--------------------------------------------------\n",
      "Question: How does the relationship between Linus and Arthur develop?\n",
      "Answer short: 1. Linus is a little jealous of Arthur's relationship with his father. 2. Linus is a little jealous of Arthur's relationship with his father. 3. Linus is a little jealous of Arthur's relationship with his father.\n",
      "\n",
      "correct answer: They evolve from acquaintances to close friends and romantic partners\n",
      "--------------------------------------------------\n",
      "Question: What prejudice do the villagers have against the orphanage?\n",
      "Answer short: 1. They think the children are all evil 2. They think the children are all dangerous\n",
      "\n",
      "correct answer: They fear and mistrust the magical children\n",
      "--------------------------------------------------\n",
      "Question: How does Linus's perspective on magical children change?\n",
      "Answer short: He now believes that they are not all bad\n",
      "\n",
      "correct answer: He learns to see them as unique individuals deserving love\n",
      "--------------------------------------------------\n",
      "Question: What is the significance of Linus's rulebook?\n",
      "Answer short: 1. No eating in the library 2. No running in the corridors 3. No magic is allowed in the corridors 4. No pets 5. No students are allowed in the staff room 6. No students are allowed to visit\n",
      "\n",
      "correct answer: It symbolizes his adherence to rules, which he begins to question\n",
      "--------------------------------------------------\n",
      "Question: How do the children impact Linus's personal growth?\n",
      "Answer short: 1. Linus learns to be more open-minded and accepting of others. 2. Linus learns to be more empathetic and compassionate towards others. 3. Linus learns to be more independent and self-reliant. 4.\n",
      "\n",
      "correct answer: They teach him about love, acceptance, and challenging norms\n",
      "--------------------------------------------------\n",
      "Question: What role does the theme of found family play in the novel?\n",
      "Answer short: 1. Harry's family is the Weasleys, 2. Harry's family is Dumbledore, 3. Harry's family is the Order of the Phoenix, 4. Harry's family is the Weasleys, 5. Harry's\n",
      "\n",
      "correct answer: It highlights that family is formed through bonds of love, not just blood\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "qa_pairs = {  \n",
    "  \"Who is the main character in The House of the Cerulean Sea?\": \"Linus Baker\",\n",
    "  \"What organization does Linus Baker work for in The House of the Cerulean Sea?\": \"The Department in Charge of Magical Youth (DICOMY)\",\n",
    "  \"What is Linus’s job title in The House of the Cerulean Sea?\": \"Caseworker\",\n",
    "  \"Who is Linus’s supervisor at DICOMY in The House of the Cerulean Sea?\": \"Mr. Werner\",\n",
    "  \"What does DICOMY monitor in The House of the Cerulean Sea?\": \"Orphanages for magical children\",\n",
    "  \"Where does Linus live at the start of the story of The House of the Cerulean Sea?\": \"A small house in a dreary city\",\n",
    "  \"What object does Linus always carry with him in The House of the Cerulean Sea?\": \"An umbrella\",\n",
    "  \"What type of report does Linus have to write after visiting an orphanage?\": \"A detailed case report\",\n",
    "  \"Who assigns Linus the task to investigate Marsyas Island Orphanage?\": \"Extremely Upper Management\",\n",
    "  \"What is unique about the Marsyas Island Orphanage?\": \"It houses magical children who are considered extremely dangerous\",\n",
    "  \"Who is the headmaster of the Marsyas Island Orphanage?\": \"Arthur Parnassus\",\n",
    "  \"What is Lucy’s special ability?\": \"He has the potential to bring chaos and destruction, but is a kind child\",\n",
    "  \"What type of magical being is Sal?\": \"A werewolf\",\n",
    "  \"What does Sal love to do in his free time?\": \"Write poetry\",\n",
    "  \"What type of magical being is Talia?\": \"A female gnome\",\n",
    "  \"What is Talia’s favorite activity?\": \"Tending to her garden\",\n",
    "  \"What type of magical creature is Chauncey?\": \"A green, amorphous tentacled blob\",\n",
    "  \"What does Chauncey dream of becoming?\": \"A bellhop\",\n",
    "  \"What type of magical being is Phee?\": \"A forest sprite\",\n",
    "  \"What does Phee feel connected to?\": \"Nature and the trees\",\n",
    "  \"Who is the oldest child at the orphanage?\": \"Sal\",\n",
    "  \"Who is the youngest child at the orphanage?\": \"Lucy\",\n",
    "  \"What is Arthur Parnassus’s secret?\": \"He is a phoenix, a magical being\",\n",
    "  \"What is Arthur’s relationship to the children?\": \"He is their protector and mentor\",\n",
    "  \"What role does Zoe Chappelwhite play on the island?\": \"She is a caretaker and protector of the children\",\n",
    "  \"What type of magical being is Zoe?\": \"A sprite\",\n",
    "  \"What is the name of the nearby village?\": \"Marsyas\",\n",
    "  \"What report does Linus have to write about Marsyas Island?\": \"An evaluation of the orphanage's safety and welfare\",\n",
    "  \"What is the significance of the cerulean sea?\": \"It symbolizes peace, beauty, and acceptance\",\n",
    "  \"What does Lucy love to play?\": \"The piano\",\n",
    "  \"What does the Extremely Upper Management request from Linus after his assignment?\": \"To submit detailed reports on the orphanage\",\n",
    "  \"What is Linus’s initial reaction to the children?\": \"He is cautious and unsure of them\",\n",
    "  \"What is the main theme of The House of the Cerulean Sea?\": \"Acceptance and understanding of differences\",\n",
    "  \"What fear does Sal struggle with?\": \"Fear of being hurt and rejected\",\n",
    "  \"What does Linus begin to see in Arthur over time?\": \"A compassionate and dedicated person\",\n",
    "  \"Who defends Linus and the children when townspeople confront them?\": \"Arthur and Zoe\",\n",
    "  \"What does Linus struggle with at his job at DICOMY?\": \"Following rigid rules over his own moral compass\",\n",
    "  \"What ultimately happens with Linus’s job at DICOMY?\": \"He decides to leave his position\",\n",
    "  \"Who provides Linus with a sense of belonging?\": \"Arthur and the children\",\n",
    "  \"What role does Linus take on by the end of the story?\": \"A parental figure to the children\",\n",
    "  \"What does Linus receive as a memento when he leaves the orphanage?\": \"A seashell\",\n",
    "  \"Who is the character that initially seems intimidating but is gentle?\": \"Lucy\",\n",
    "  \"How does Arthur respond to threats against the children?\": \"With calm and diplomacy\",\n",
    "  \"What is the main conflict Linus faces during his assignment?\": \"Balancing his duty to DICOMY with his growing affection for the children\",\n",
    "  \"How does the relationship between Linus and Arthur develop?\": \"They evolve from acquaintances to close friends and romantic partners\",\n",
    "  \"What prejudice do the villagers have against the orphanage?\": \"They fear and mistrust the magical children\",\n",
    "  \"How does Linus's perspective on magical children change?\": \"He learns to see them as unique individuals deserving love\",\n",
    "  \"What is the significance of Linus's rulebook?\": \"It symbolizes his adherence to rules, which he begins to question\",\n",
    "  \"How do the children impact Linus's personal growth?\": \"They teach him about love, acceptance, and challenging norms\",\n",
    "  \"What role does the theme of found family play in the novel?\": \"It highlights that family is formed through bonds of love, not just blood\"\n",
    "}\n",
    "\n",
    "icl = read_json(knowmem_forget_qa_icl_file)\n",
    "icl_qs=[d['question'] for d in icl]\n",
    "icl_as=[d['answer'] for d in icl]\n",
    "\n",
    "answers_icl = {}\n",
    "general_prompt: str = \"\"\n",
    "\n",
    "# Few-shot prompting\n",
    "for question, answer in zip(icl_qs, icl_as):\n",
    "    general_prompt += f\"Question: {question}\\nAnswer: {answer}\\n\\n\"\n",
    "\n",
    "answers = {}\n",
    "for question, answer in qa_pairs.items():\n",
    "    print(f\"Question: {question}\")\n",
    "    # Set the maximum number of new tokens to generate\n",
    "    max_new_tokens = 50\n",
    "\n",
    "    # Create the prompt for the model\n",
    "    # prompt = question\n",
    "    prompt = general_prompt + f\"Question: {question}\\nAnswer: \"\n",
    "\n",
    "    # Encode the `prompt` into `input_ids`\n",
    "    input_ids = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors='pt',\n",
    "        add_special_tokens=True).input_ids\n",
    "\n",
    "    # Use the `model` to generate the continuation of the `input_ids`.\n",
    "    output_ids = model.generate(\n",
    "        input_ids.to(model.device),\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=False,\n",
    "        pad_token_id=tokenizer.pad_token_id)\n",
    "    output_ids = output_ids[:, len(input_ids[0]):]\n",
    "\n",
    "    output = tokenizer.batch_decode(\n",
    "        output_ids,\n",
    "        skip_special_tokens=True,\n",
    "        clean_up_tokenization_spaces=True)[0]\n",
    "\n",
    "    answers[question] = output\n",
    "\n",
    "    stripped_output = get_prefix_before_words_occur(output, [\"\\n\\n\", \"\\nQuestion\", \"Question:\"])\n",
    "    answers_icl[question] = stripped_output.strip()\n",
    "\n",
    "for question, answer in qa_pairs.items():\n",
    "    print(f\"Question: {question}\")\n",
    "    # print(f\"Answer: {answers[question]}\\n\")\n",
    "    print(f\"Answer short: {answers_icl[question]}\\n\")\n",
    "    print(f'correct answer: {answer}')\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302d413d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
